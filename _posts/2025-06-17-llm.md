---
layout: single
title: "[Data Science Project] Amazon Magazine Subscription Review Data Analysis: Topic Modeling Techniques on LDA, BERTopic, and LLM-based QualIt"
toc: true
categories: project
comments: true
thumbnail: https://gomediashark.com/wp-content/uploads/2024/05/How-to-Get-Amazon-Reviews-the-Right-Way.png
---

# Introduction

LLM, or Large Language Model, is a trained deep learning model that utilizes a vast amount of data. 
This project explores how different Topic Modeling approaches are: LDA, BERTopic, and a Large Language Model (LLM), enhanced method inspired by **QualIT** (Karpoor et al. 2024). 
Based on Magazine subscription of Amazon magzine review data, this project performs a Topic Modeling to extract the keywords and cluster the reviews by each characteristics.

## How do LLMs Work?

LLM represent words using **vector embeddings** and learn to predict the next word in a sequence. During training, the model updates parameters to maximize the  likelihood of correct predictions, 
a process known as self-supervised learning. Once trained, LLMs can:

- Answer questions

- Translate languages

- Summarize documents

- Write code or articles

![AWS Review](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTuUR_DJPpUk_UQpy8tHXICT3aC1v1pcD3sfw&s)

## Why are LLMs Important?

LLMs power generative AI, assist in **customer service**, support **content creation**, and are redefining **knowledge retrieval** and **developer productivity**.

## Real-World Applications

- Copywriting and marketing content

- Customer sentiment analysis

- Text classification

- Code generation (e.g., GitHub Copilot, CodeWhisperer)

- Conversational AI (e.g., ChatGPT, Alexa)

## The Future of LLMs

LLMs are expected to evolve with:

- Better accuracy and bias reduction

- Multimodal training (text, image, audio)

- Wider workplace automation

- Smarter, more interactive virtual assistants

If you want more information, click this link here: [LLM on AWS](https://aws.amazon.com/what-is/large-language-model/)

# Kapoor et al. (2024)

The core inspiration for this project is 

## Research question, research gap

## Method

## Result + interpretation

# Data introduction

For this project, I utilized customer review data collected by Amazon, specifically focusing on magazine subscriptions. 
These reviews are rich in natural language content and highly suitable for testing topic modeling techniques.

## Data sources

The dataset was obtained from the publicly available UCSD Amazon Review Dataset:

- UCSD Amazon Review Dataset:

[CLICK](https://cseweb.ucsd.edu/~jmcauley/datasets.html)

- File used: ``Magazine_Subscriptions.jsonl``

## Major characteristics of the data 

- Fields:

  - ``rating`` (float: from 1.0 to 5.0)
  - ``title`` (Title of the review)
  - ``text`` (main review body)
  - ``asin``, ``timestamp``, and other metadata

- Langauge: ``English``

- Document type: Free-text customer reviews

- Structure: Highly diverse in tone, length, and writing style

- Size: ~71,500 records

This variety in user-generated content makes the dataset particularly challenging and valuable for exploring different topic modeling strategies.


## data pre-processing

To ensure consistency across all models, a **unified preprocessing pipeline** was implemented. The main steps included:

- Removing extra whitespace

- Stripping emails and apostrophes

- Filtering out non-alphabet characters

- Converting all text to lowercase

Hereâ€™s the preprocessing function used:

```python
import re

# Preprocess the text data
def preprocess_text(text):
    text = re.sub('\s+', ' ', str(text))  # Remove extra spaces
    text = re.sub('\S*@\S*\s?', '', str(text))  # Remove emails
    text = re.sub('\'', '', str(text))  # Remove apostrophes
    text = re.sub('[^a-zA-Z]', ' ', str(text))  # Remove non-alphabet characters
    text = text.lower()  # Convert to lowercase
    return text
data['cleaned_text'] = data['text'].apply(preprocess_text)
```
- Tokenized using ``gensim``
- Stopwords removed using ``nltk``

# Analysis

## Explanation of analysis

## Showing codes + results

## Interpretation

# Thank you for reading!
