---
layout: single
title: "[Data Science Project] Amazon Magazine Subscription Review Data Analysis: Topic Modeling Techniques on LDA, BERTopic, and LLM-based QualIT 2"
toc: true
categories: project
comments: true
thumbnail: https://gomediashark.com/wp-content/uploads/2024/05/How-to-Get-Amazon-Reviews-the-Right-Way.png
---

# Previous page

This page is connected to the previous post. If you read this post for the first time, please click this link: [CLICK](https://jlee400.github.io/project/llm/)


# LLM (QualIT)

QualIT: Qualitative Insights Tool is presented in ``Kapoor et al. (2024)`` to extend the capabilities of existing topic models. This approach integrates pre-trained LLMs with clustering techniques to systematically address the limitations of both methods and generate more nuanced and interpretable topic representations from free-text data. QualIT complements the analysis step that takes too much time, about 3 months per project, to take one month of a researcher's time per project. 

Unlike traditional topic modeling approaches that rely on hand-crafted features or simple statistical patterns, LLMs can capture complex semantic and syntactic relationships within language, allowing them to better handle the nuances and ambiguities inherent in real-world text. 

## LLM Analysis of Amazon Review Data

To extract concise and meaningful key phrases from customer reviews, I created a custom function using prompt engineering. This function is designed to guide a language model (GPT-3.5 turbo) to return phrases that best represent the main topics, experiences, and product features mentioned in the text.

```python
# Prompt
def extract_keyphrases(text, index=None, total=None):
    if index is not None and total is not None:
        print(f"{index + 1} / {total}")

    prompt = f"""Analyze the following customer review and extract 5 to 10 key phrases that best represent the core topics, features, sentiments, and experiences mentioned in the review.

    Key phrases should capture the main subjects, specific product or service attributes, common issues, or positive aspects.

    Guidelines:
    - Each extracted phrase must clearly represent a specific point or idea from the review.
    - Formulate them as meaningful phrases, not just single words or a list of adjectives/verbs.
    - For example: "poor battery life", "excellent customer support", "difficult assembly process".
    - Output should be a single line, with key phrases separated by commas.
    - DO NOT include explanatory sentences, adjectives, adverbs, verbs, or full sentences.
    - The extracted key phrases will be used for subsequent document clustering and topic summarization.
    

    [Customer Review]
    {text}

    Key Phrases:"""
    #return gemini_prompt(prompt)
    return gpt_prompt(prompt)
```

By enforcing phrase-level outputs and avoiding vague words or full sentences, the results are clean, interpretable, and ready for downstream analysis.


### Clustering


 Top keywords by cluster:

Cluster 0: love / magazine / it / this / like / kids / articles / baby / favorite / granddaughter / grandson / ideas / item / was / loved / loves / new / reading / renew / she
Cluster 1: subscription / remainder / published / publication / of / nast / magazine / issues / gourmet / ending / conde / annual
Cluster 2: magazine / great / articles / good / reading / to / positive / subscription / and / content / section / enjoyable / read / the / love / received / for / christmas / feedback / experience
Cluster 3: magazine / content / and / for / recipes / to / cover / articles / interesting / information / of / editorial / stories / not / quality / cooking / pop / the / yoga / positive
Cluster 4: subscription / renewal / magazine / service / customer / issue / delivery / issues / cancellation / amazon / no / to / renew / about / not / for / automatic / experience / pricing / of

## Topic Evaluation Metrics (BERTopic)

**Coherence Score (N=20): 0.3805**

The coherence score measures the semantic similarity among the top keywords within each topic. A higher coherence score indicates that the words in a topic tend to co-occur together in the original corpus, making the topic more interpretable and meaningful.

In this case, the coherence score of 0.3805 is moderate, suggesting that the topics are reasonably coherent, but there may be room for improvement.

This score is influenced by factors such as the choice of embedding model, the number of topics, and how distinct the themes in the reviews are.

**Diversity Score (N=20): 0.5444**

The diversity score evaluates how distinct the top words are across different topics. A high diversity score means that the topics are not repeating the same words, and each topic brings unique information.

Here, the diversity score is 0.5444, which is relatively low to moderate. This means that while some topics have unique vocabulary, thereâ€™s also overlap across topics, which may indicate semantic redundancy or insufficient topic separation.


# Thank you for reading!

I hope this helped you better understand topic modeling with LLMs. If you're curious about NLP, data science, or AI experiments like this one, **subscribe** and stay tuned for more deep dives!

ðŸ’¡ Suggestions or questions? Iâ€™d love to hear from you in the comments!

![ì›€ì§¤](https://blog.kakaocdn.net/dn/bMg4z6/btqQu5croUb/eC9M7QNNaBDAA52pBQoS8K/img.gif)



